{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import *\n",
    "import xarray as xr\n",
    "%reload_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3515, 5510)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = xr.open_rasterio(\"nasadem_sd.tif\")\n",
    "da.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Profiling sparse weight builders for raster data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lat2SW` is very performant since it creates regular lattice without any missing values to deal with. It straight away creates diagonals and offsets which are then shipped to dia matrix constructor.\n",
    "Memory consumpttion is high due to use of `list` instead of `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4134.30 MiB, increment: 3859.86 MiB\n"
     ]
    }
   ],
   "source": [
    "# memory profiling vanilla lat2SW\n",
    "%memit lat2SW(*da[0].shape, \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.47 s ± 489 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# perf-testing vanilla lat2SW\n",
    "%timeit lat2SW(*da[0].shape, \"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is `da2WSP` which uses `lat2SW` to build sparse matrix and then through boolean indexing it removes missing rows and columns from the created matrix.\n",
    "Performance takes a hit due to boolean indexing of csr matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4208.72 MiB, increment: 3933.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit da2WSP(da, \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.18 s ± 72.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit da2WSP(da, \"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create matrix with only non missing values in mind, `lat2SW`/`dia_matrix` was out of question since it is higly oriented towards building regular lattice.\n",
    "\n",
    "Next options were to build either [DOK](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.dok_matrix.html#scipy.sparse.dok_matrix), [CSR/CSC](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix), or [COO](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html#scipy.sparse.coo_matrix)...\n",
    "\n",
    "- It was impossible (for me) to Numba-fy `DOK` builder due to its structure and without numba it was too slow.\n",
    "- In case of `CSR/CSC` I was not able to think of a multithreaded implementation (still exploring a way to build this)\n",
    "- From the start I was biased towards `COO` as it's structure is quite simple, can be numba-fied, farely easy to incorporate multithreading and fast conversion to `CSR/CSC` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3121.64 MiB, increment: 2758.57 MiB\n"
     ]
    }
   ],
   "source": [
    "# memory profiling COO based da2WSP\n",
    "%memit da2WSP2(da, \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.13 s ± 284 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# perf-testing COO based da2WSP\n",
    "%timeit da2WSP2(da, \"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still working on parallel implementation as this is only single threaded, right now it initializes row and col arrays each of dtype=uint32 (can hold a raster of size upto 65535x65535) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da2WSP2(da, criterion=\"rook\", band=None):\n",
    "    band = da_checker(da, band)\n",
    "    da = da[band-1:band]\n",
    "    ser = da.to_series()\n",
    "    mask = (ser != da.nodatavals[0]).to_numpy()\n",
    "    ids = np.where(mask)[0]\n",
    "    row, col, data = _swbuilder(*da[0].shape, ids, mask, criterion)\n",
    "    n = len(ids)\n",
    "    sw = sparse.coo_matrix((data, (row, col)), shape=(n, n), dtype=np.int8).tocsr()\n",
    "    ser = ser[ser != da.nodatavals[0]]\n",
    "    index = ser.index\n",
    "    wsp = WSP(sw, index=index)\n",
    "    return wsp\n",
    "\n",
    "\n",
    "@njit\n",
    "def _swbuilder(nrows, ncols, ids, mask, criterion):\n",
    "    n = len(ids)\n",
    "    mask = mask * 1\n",
    "    mask[ids] = np.arange(len(ids), dtype=np.uint32)\n",
    "    d = 4 if criterion == \"rook\" else 8\n",
    "    rows = np.empty(d*n, dtype=np.uint32)\n",
    "    cols = np.empty(d*n, dtype=np.uint32)\n",
    "    j = 0\n",
    "    for i in prange(n):\n",
    "        k = ids[i]\n",
    "        if ((k+1) % ncols) != 0:\n",
    "            r = mask[k + 1]\n",
    "            if r:\n",
    "                rows[j], cols[j] = i, r\n",
    "                j += 1\n",
    "                rows[j], cols[j] = r, i\n",
    "                j += 1\n",
    "        if (k // ncols) < (nrows - 1):\n",
    "            r = mask[k+ncols]\n",
    "            if r:\n",
    "                rows[j], cols[j] = i, r\n",
    "                j += 1\n",
    "                rows[j], cols[j] = r, i\n",
    "                j += 1\n",
    "        if criterion == \"queen\":\n",
    "            if (k // ncols) < (nrows - 1):\n",
    "                if (k % ncols) != 0:\n",
    "                    r = mask[k+ncols-1]\n",
    "                    if r:\n",
    "                        rows[j], cols[j] = i, r\n",
    "                        j += 1\n",
    "                        rows[j], cols[j] = r, i\n",
    "                        j += 1\n",
    "                if ((k+1) % ncols) != 0:\n",
    "                    r = mask[k+ncols+1]\n",
    "                    if r:\n",
    "                        rows[j], cols[j] = i, r\n",
    "                        j += 1\n",
    "                        rows[j], cols[j] = r, i\n",
    "                        j += 1\n",
    "    rows = rows[:j]\n",
    "    cols = cols[:j]\n",
    "    data = np.ones(j, dtype=np.int8)\n",
    "    return rows, cols, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}